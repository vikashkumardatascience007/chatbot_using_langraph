{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict, Annotated\n",
    "from langchain_core.messages import BaseMessage,HumanMessage\n",
    "from langchain_community.chat_models import ChatOllama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph.message import add_messages\n",
    "class ChatState(TypedDict):\n",
    "    messages:Annotated[list[BaseMessage], add_messages]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatOllama(model=\"mistral:latest\",\n",
    "    temperature=0.2)\n",
    "\n",
    "def chat_node(state:ChatState):\n",
    "\n",
    "    # take user uery state\n",
    "    messages=state['messages']\n",
    "\n",
    "    # send to llm\n",
    "    response=llm.invoke(messages)\n",
    "\n",
    "    # response store state\n",
    "    return {'messages':[response]}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add memory in loop of chat\n",
    "from langgraph.checkpoint.memory import MemorySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = MemorySaver()\n",
    "\n",
    "graph = StateGraph(ChatState)\n",
    "graph.add_node(\"chat_node\", chat_node)\n",
    "graph.add_edge(START, \"chat_node\")\n",
    "graph.add_edge(\"chat_node\", END)\n",
    "\n",
    "chatbot = graph.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state={\n",
    "    'messages':[HumanMessage(content='What is capital of india')]\n",
    "}\n",
    "# chatbot.invoke(initial_state)['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USer: hi iam vikash \n",
      "AI:  Hello Vikash! How can I assist you today?\n",
      "USer: what is my name\n",
      "AI:  Your name, as per the greeting you provided earlier, is Vikash. Is there something specific you would like to know or discuss related to your name or any other topic?\n",
      "USer: exit\n"
     ]
    }
   ],
   "source": [
    "thread_id = \"1\"\n",
    "\n",
    "while True:\n",
    "    user_message = input(\"Type here: \")\n",
    "\n",
    "    print('USer:', user_message)\n",
    "\n",
    "    if user_message.strip().lower() in [\"exit\", \"quit\", \"bye\"]:\n",
    "        break\n",
    "\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "    response = chatbot.invoke(\n",
    "        {\"messages\": [HumanMessage(content=user_message)]},\n",
    "        config=config\n",
    "    )\n",
    "\n",
    "    print(\"AI:\", response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
