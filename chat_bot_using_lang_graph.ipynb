{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict, Annotated\n",
    "from langchain_core.messages import BaseMessage,HumanMessage\n",
    "from langchain_community.chat_models import ChatOllama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph.message import add_messages\n",
    "class ChatState(TypedDict):\n",
    "    messages:Annotated[list[BaseMessage], add_messages]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vikash.vk.kumar\\AppData\\Local\\Temp\\ipykernel_14308\\2102244441.py:1: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the `langchain-ollama package and should be used instead. To use it run `pip install -U `langchain-ollama` and import as `from `langchain_ollama import ChatOllama``.\n",
      "  llm=ChatOllama(model=\"mistral:latest\",\n"
     ]
    }
   ],
   "source": [
    "llm=ChatOllama(model=\"mistral:latest\",\n",
    "    temperature=0.2)\n",
    "\n",
    "def chat_node(state:ChatState):\n",
    "\n",
    "    # take user uery state\n",
    "    messages=state['messages']\n",
    "\n",
    "    # send to llm\n",
    "    response=llm.invoke(messages)\n",
    "\n",
    "    # response store state\n",
    "    return {'messages':[response]}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add memory in loop of chat\n",
    "from langgraph.checkpoint.memory import MemorySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer=MemorySaver()\n",
    "\n",
    "graph=StateGraph(ChatState)\n",
    "graph.add_node('chat_node',chat_node)\n",
    "graph.add_edge(START,'chat_node')\n",
    "graph.add_edge('chat_node',END)\n",
    "\n",
    "chatbot=graph.compile(checkpointer=checkpointer)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" The capital of India is New Delhi. It serves as the center of the executive, legislative, and judicial branches of the Government of India. However, it's important to note that New Delhi is not one of the states of India, but a union territory and acts as the seat of the federal government. The largest city and commercial hub of India is Mumbai (formerly known as Bombay).\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_state={\n",
    "    'messages':[HumanMessage(content='What is capital of india')]\n",
    "}\n",
    "chatbot.invoke(initial_state)['messages'][1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3135279583.py, line 12)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mresponse=chatbot.invoke({'messages':[HumanMessage(content=user_message)]}, config:config)\u001b[39m\n                                                                                     ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "thread_id=\"1\"\n",
    "while True:\n",
    "\n",
    "    user_message= input('Type here:...... ')\n",
    "    print('USer:', user_message)\n",
    "\n",
    "    if user_message.strip().lower() in ['exit','quit','bye']:\n",
    "        break\n",
    "\n",
    "    config={'configurable':{'thread_id':thread_id}}\n",
    "\n",
    "    response=chatbot.invoke({'messages':[HumanMessage(content=user_message)]}, config:config)\n",
    "\n",
    "    print('AI: ', response['messages'][1].content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
